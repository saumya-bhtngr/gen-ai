{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPHdwHuo/VmJL/zpDKJdVPC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Objective:\n","\n","This file implements evaluation harness that automatically scores an LLM's output across multiple evalutaion criteria.\n","*   Automate scoring mechanism as the LLM system evolves\n","*   Evaluation criteria include accurcay, relevance, completeness, tone\n","*   Each criteria is scored on a scale of 1-5"],"metadata":{"id":"DsXovAjrZCXY"}},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HtP9KEFxK6O6","executionInfo":{"status":"ok","timestamp":1772183249110,"user_tz":-480,"elapsed":5797,"user":{"displayName":"Saumya Bhatnagar","userId":"08670837497643728443"}},"outputId":"dfd2f975-8fad-4cba-c546-24319d10586b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.23.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.13.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.3)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n","Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"]}],"source":["!pip install openai"]},{"cell_type":"code","source":["from dataclasses import dataclass\n","import openai\n","import json"],"metadata":{"id":"2D2e_PZsP6I0","executionInfo":{"status":"ok","timestamp":1772183254339,"user_tz":-480,"elapsed":3,"user":{"displayName":"Saumya Bhatnagar","userId":"08670837497643728443"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["from google.colab import userdata\n","openai_api_key = userdata.get(\"OPENAI_API_KEY\").strip()"],"metadata":{"id":"T-Wcr-n2QBNr","executionInfo":{"status":"ok","timestamp":1772183255891,"user_tz":-480,"elapsed":654,"user":{"displayName":"Saumya Bhatnagar","userId":"08670837497643728443"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["# below is the source document and hypothetical responses given by LLM\n","SOURCE_DOCUMENT = \"\"\"\n","Policy Number: CYB-2024-10234.\n","This cyber liability policy covers data breaches, ransomware attacks,\n","and business interruption losses up to $5 million per occurrence.\n","The retroactive date is January 1, 2022.\n","Exclusions include: war, nuclear events, and intentional acts by the insured.\n","Annual premium: $48,000. Renewal date: December 31, 2024.\n","\"\"\"\n","\n","# The question asked\n","QUESTION = \"What does this cyber policy cover and what are its exclusions?\"\n","\n","# A good answer (what we hope the LLM produces)\n","GOOD_ANSWER = \"\"\"\n","This cyber liability policy covers data breaches, ransomware attacks,\n","and business interruption losses up to $5 million per occurrence.\n","It excludes war, nuclear events, and intentional acts by the insured.\n","\"\"\"\n","\n","# A bad answer (vague, incomplete)\n","BAD_ANSWER = \"\"\"\n","The policy covers various cyber risks and has some exclusions\n","related to certain events. Coverage is available for incidents.\n","\"\"\"\n","\n","# A hallucinated answer (makes up facts not in the document)\n","HALLUCINATED_ANSWER = \"\"\"\n","This cyber policy covers data breaches and ransomware attacks up to $10 million.\n","It also covers physical damage to hardware and employee theft.\n","Exclusions include acts of God and pandemics.\n","\"\"\""],"metadata":{"id":"gFyFM-69RvtL","executionInfo":{"status":"ok","timestamp":1772183370075,"user_tz":-480,"elapsed":2,"user":{"displayName":"Saumya Bhatnagar","userId":"08670837497643728443"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["from dataclasses import dataclass\n","import openai\n","import json\n","\n","@dataclass\n","class EvaluationClass():\n","  \"\"\" Structured container for evaluation scores \"\"\"\n","  accuracy: int             # 1-5 how correct LLM's response is with respect to source document\n","  relevance: int            # 1-5 is the response relevant to the user's query\n","  completeness: int         # 1-5 does the response contain all the required information\n","  tone: int                 # 1-5 is the response language professional\n","  overall: int              # average of above scores\n","  feedback: str             # one-line evaluation summary\n","\n","def evaluate_response(question: str, source_document: str, llm_response: str) -> EvaluationClass:\n","  \"\"\" Evaluates LLM's response using four criteria using another LLM.\n","  response is returned in JSON format (machine readable and easy to store in database for tracking) \"\"\"\n","\n","  prompt = f\"\"\" You are an expert evaluator of LLM response insurance domain. Your job is to rate the LLM's\n","  response using four criteria. Only use original source document for evaluation and DO NOT use external information\n","  -----\n","  Question: {question}\n","  Source Document (ground truth): {source_document}\n","  Answer to evaluate: {llm_response}\n","  -----\n","  Score each answer from 1-5 on below four criteria:\n","  Accuracy (how factually correct LLM's response is with respect to source document?):\n","  5 - Perfectly factually correct, no errors\n","  3 - Partially correct or has some mistakes\n","  1 - Not correct or has made-up information\n","\n","  Relevance (does the answer address user query?):\n","  5 - Very relevant, addresses the user query completely\n","  3 - Partially addresses the user query\n","  1 - Does not address the user query\n","\n","  Completeness (does the answer answer all parts of user question?):\n","  5 - Addresses the user query completely\n","  3 - Covers some parts of the user query and not all\n","  1 - Barely answers the user query\n","\n","  Tone (does the answer sound professional for insurance context?)\n","  5 - the tone of the answer is professional and clear\n","  3 - the tone is somewhat formal but can be improved\n","  1 - the tone is not at all professional\n","\n","  Your response should ONLY follow below JSON format and DO NOT add additional information\n","  {{\n","    accuracy <score 1-5>\n","    relevance <score 1-5>\n","    completeness <score 1-5>\n","    tone <score 1-5>\n","    feedback <one line sentence describing strength or weakness of the answer>\n","  }}\n","  \"\"\"\n","\n","  client = openai.OpenAI(api_key=openai_api_key)\n","  response = client.chat.completions.create(\n","      model=\"gpt-4-turbo\",\n","      messages=[\n","          {\"role\": \"user\", \"content\": prompt}\n","      ],\n","      temperature=0         # 0 for evaluation since we want consistency\n","  )\n","\n","  raw_text = response.choices[0].message.content\n","  output_scores = json.loads(raw_text)\n","  overall_score = (output_scores[\"accuracy\"] + output_scores[\"relevance\"] + output_scores[\"completeness\"] + output_scores[\"tone\"]) / 4\n","\n","  return EvaluationClass(\n","      accuracy= output_scores[\"accuracy\"],\n","      relevance= output_scores[\"relevance\"],\n","      completeness= output_scores[\"completeness\"],\n","      tone= output_scores[\"tone\"],\n","      overall = round(overall_score, 2),\n","      feedback= output_scores[\"feedback\"]\n","  )"],"metadata":{"id":"4U5iiUH7QNie","executionInfo":{"status":"ok","timestamp":1772183829109,"user_tz":-480,"elapsed":8,"user":{"displayName":"Saumya Bhatnagar","userId":"08670837497643728443"}}},"execution_count":69,"outputs":[]},{"cell_type":"code","source":["def run_evaluation_harness(test_cases: list[dict]) -> None:\n","  print(\"*\"*50)\n","  print(\"Evaluation Summary\")\n","  print(\"*\"*50)\n","  results = []\n","  for test_case in test_cases:\n","    print(\"Evaluating case: \", test_case[\"label\"])\n","    question = test_case[\"question\"]\n","    source_document = test_case[\"source_document\"]\n","    llm_response = test_case[\"llm_response\"]\n","\n","    evaluation_result = evaluate_response(question, source_document, llm_response)\n","    results.append((test_case[\"label\"], evaluation_result))\n","\n","    # print evaluation results\n","    print(f\"Accuracy: {evaluation_result.accuracy}\")\n","    print(f\"Relevance: {evaluation_result.relevance}\")\n","    print(f\"Completeness: {evaluation_result.completeness}\")\n","    print(f\"Tone: {evaluation_result.tone}\")\n","    print(f\"Overall: {evaluation_result.overall}\")\n","    print(f\"Feedback: {evaluation_result.feedback}\")"],"metadata":{"id":"8ZMaDNs4iKXU","executionInfo":{"status":"ok","timestamp":1772183830036,"user_tz":-480,"elapsed":5,"user":{"displayName":"Saumya Bhatnagar","userId":"08670837497643728443"}}},"execution_count":70,"outputs":[]},{"cell_type":"code","source":["if __name__== \"__main__\":\n","  test_cases = [\n","      {\n","          \"label\": \"Good Answer\",\n","          \"question\": QUESTION,\n","          \"source_document\": SOURCE_DOCUMENT,\n","          \"llm_response\": GOOD_ANSWER\n","      },\n","      {\n","          \"label\": \"Bad Answer\",\n","          \"question\": QUESTION,\n","          \"source_document\": SOURCE_DOCUMENT,\n","          \"llm_response\": BAD_ANSWER\n","      },\n","      {\n","          \"label\": \"Hallucinated Answer\",\n","          \"question\": QUESTION,\n","          \"source_document\": SOURCE_DOCUMENT,\n","          \"llm_response\": HALLUCINATED_ANSWER\n","      }\n","  ]\n","\n","  run_evaluation_harness(test_cases)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yIMy1ckmiJFM","executionInfo":{"status":"ok","timestamp":1772183839231,"user_tz":-480,"elapsed":8167,"user":{"displayName":"Saumya Bhatnagar","userId":"08670837497643728443"}},"outputId":"f50514f9-f9e0-4e08-b258-5a272c29e594"},"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["**************************************************\n","Evaluation Summary\n","**************************************************\n","Evaluating case:  Good Answer\n","Accuracy: 5\n","Relevance: 5\n","Completeness: 5\n","Tone: 5\n","Overall: 5.0\n","Feedback: The response accurately and completely addresses the query with a professional tone.\n","Evaluating case:  Bad Answer\n","Accuracy: 3\n","Relevance: 3\n","Completeness: 2\n","Tone: 4\n","Overall: 3.0\n","Feedback: The response is somewhat accurate and relevant but lacks specific details and completeness.\n","Evaluating case:  Hallucinated Answer\n","Accuracy: 1\n","Relevance: 3\n","Completeness: 1\n","Tone: 5\n","Overall: 2.5\n","Feedback: The response includes incorrect details and omits key information from the source document.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"CKCPw8bsR7zS"},"execution_count":null,"outputs":[]}]}